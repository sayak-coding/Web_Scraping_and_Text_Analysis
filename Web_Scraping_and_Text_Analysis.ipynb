{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1qzyCy0S-NPsBmJGD3imSH_cS1Dvcj4cM",
      "authorship_tag": "ABX9TyPgV4noEQY3c2EaQmKgDiSk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayak-coding/Web_Scraping_and_Text_Analysis/blob/main/Web_Scraping_and_Text_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install textstat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDT3si9ZKv8a",
        "outputId": "25a689a9-6efb-4462-8b2b-048c9900f8e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textstat in /usr/local/lib/python3.10/dist-packages (0.7.3)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.10/dist-packages (from textstat) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2RcB-4ZKUl0"
      },
      "outputs": [],
      "source": [
        "# import the required libraries\n",
        "\n",
        "import pandas as pd # Python package for dealing with data structures  \n",
        "import numpy as np # numerical python for linear algebra\n",
        "import openpyxl  # a Python library for reading and writing Excel \n",
        "import requests # Requests will allow you to send HTTP/1.1 requests using Python                           \n",
        "from bs4 import BeautifulSoup # for web scraping purposes to pull the data from a html website \n",
        "from textblob import TextBlob # for processing textual data   \n",
        "import textstat  # to calculate statistics from text                              \n",
        "import string  # package to process standard Python strings  \n",
        "import re # provides full support for regular expression                \n",
        "import spacy # for Industrial strength advanced NLP in Python                 \n",
        "import nltk # toolkit build for working with NLP in Python     \n",
        "from nltk.tokenize import word_tokenize # import module for tokenization from nltk \n",
        "from nltk.corpus import stopwords # import module for stopwords from nltk             "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt') # downloading punctuations from nltk \n",
        "nltk.download('stopwords') # dowloading stopwords from nltk \n",
        "nltk.download('averaged_perceptron_tagger') # downloading average perceptron tagger from nltk "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oSv39ecK96u",
        "outputId": "2fafc7c3-5d07-4567-978f-90d5a9d6d5e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# open the file where positive words are stored \n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Blackcoffer Data Engineer Assignment/20211030 Test Assignment-20230525T172247Z-001/20211030 Test Assignment/MasterDictionary/positive-words.txt\",\"r\") as pos:\n",
        "    positive_words = pos.read().split(\"\\n\") \n",
        "    \n",
        "# open the file where negative words are stored \n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/Blackcoffer Data Engineer Assignment/20211030 Test Assignment-20230525T172247Z-001/20211030 Test Assignment/MasterDictionary/negative-words.txt\",\"r\",encoding = \"ISO-8859-1\") as neg:\n",
        "    negative_words = neg.read().split(\"\\n\")"
      ],
      "metadata": {
        "id": "NW3HW0VHLWiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=[] # initialize article text with a blank list \n",
        "\n",
        "def Text_Analysis(): # define a function 'text_analysis'\n",
        "\n",
        "    # fetching data from given input excel sheet \n",
        "    workbook = openpyxl.load_workbook('/content/drive/MyDrive/Colab Notebooks/Blackcoffer Data Engineer Assignment/20211030 Test Assignment-20230525T172247Z-001/20211030 Test Assignment/Input.xlsx')  \n",
        "    worksheet = workbook['Sheet1']\n",
        "    \n",
        "    # fetching the url from sheet into url variable \n",
        "    for i in range (2 , 116): # as we have only 115 url \n",
        "        url_id = int(worksheet.cell(row=i, column=1).value)\n",
        "        url = (worksheet.cell(row=i, column=2).value) # iterate on second column and ith row\n",
        "        \n",
        "        #We need to pass argument called Headers by passing \"User-Agent\" to the request to bypass the mod-security error.\n",
        "        headers = {\"User-Agent\": \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/60.0 Chrome/108.0.0.0 Safari/537.36\"} \n",
        "        # header = {'User-Agent': \"Mozilla/5.0 (X11; Linux x86_64; rv:60.0; Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36 Gecko/20100101 Firefox/60.0\"}    \n",
        "        response = requests.get(url, headers=headers) # make a request to url\n",
        "    \n",
        "    # apply BeautifulSoup to fetch only html parser \n",
        "        soup = BeautifulSoup(response.content, 'html.parser') \n",
        "        \n",
        "    \n",
        "        # fetch title from link\n",
        "        try:\n",
        "          # title = soup.find('h1',class_=\"entry-title\").text.replace('\\n',\" \")\n",
        "          title = soup.find('h1').get_text()\n",
        "        except:\n",
        "          continue\n",
        "\n",
        "        #fetch content from link and remove unwanted header & punctuation\n",
        "        article = soup.findAll(attrs={'class':'td-post-content'})    \n",
        "        article = article[0].text.replace('\\n',\" \")    \n",
        "        article = article.translate(str.maketrans('', '', string.punctuation)) \n",
        "    \n",
        "        #tokenize the data \n",
        "        text_tokens = word_tokenize(article)\n",
        "           \n",
        "        #remove stopwords\n",
        "        stop_words = stopwords.words('english')\n",
        "        stop_tokens = [word for word in text_tokens if not word in stop_words]\n",
        "    \n",
        "        #count positive score usnig positive dictionary \n",
        "        positive_word_count = \" \".join ([w for w in stop_tokens if w in positive_words])   \n",
        "        positive_word_count=positive_word_count.split(\" \")  \n",
        "        Positive_score=len(positive_word_count)\n",
        "    \n",
        "        #count negative score usnig negative dictionary\n",
        "        negative_word_count = \" \".join ([w for w in stop_tokens if w in negative_words])    \n",
        "        negative_word_count=negative_word_count.split(\" \")    \n",
        "        Negative_score=len(negative_word_count)\n",
        "        \n",
        "        #join filter data after removing stpowords  \n",
        "        filter_article = ' '.join(stop_tokens)\n",
        "        \n",
        "        #words count \n",
        "        Word_Count=len(article)\n",
        "        \n",
        "        #Average_Sentence_Length count \n",
        "        Average_Sentence_Length = len(article.replace(' ',''))/len(re.split(r'[?!.]', article))\n",
        "    \n",
        "        #calculating fog index using textstat library\n",
        "        Fog_Index=(textstat.gunning_fog(article)) # fog index\n",
        "    \n",
        "        #Average_Number_of_Words_Per_Sentence count\n",
        "        Average_Number_of_Words_Per_Sentence = [len(l.split()) for l in re.split(r'[?!.]', article) if l.strip()]\n",
        "        Average_Number_of_Words_Per_Sentence=(sum(Average_Number_of_Words_Per_Sentence)/len(Average_Number_of_Words_Per_Sentence))\n",
        "    \n",
        "        Word_Count=len(article) # count the words\n",
        "       \n",
        "        #function to calculate Complex_Words consedring word not ending from \"ed\" or \"es\"\n",
        "        def Complex_Count(word):\n",
        "            count = 0\n",
        "            vowels = \"AEIOUYaeiouy\"\n",
        "            if word[0] in vowels:\n",
        "                count = count + 1\n",
        "            for index in range(1, len(word)): \n",
        "                    if word[index] in vowels and word[index - 1] not in vowels:\n",
        "                        count = count + 1\n",
        "                        if word.endswith(\"es\"or \"ed\"):\n",
        "                            count = count - 1\n",
        "            if count == 0:\n",
        "                count = count + 1\n",
        "            return count\n",
        "        Complex_Word_Count = Complex_Count(article) # complex word \n",
        "\n",
        "    \n",
        "        #function to calculate proper noun in article with help of tagging from nltk lib\n",
        "        def Proper_Noun_Extractor(text):\n",
        "            count = 0\n",
        "            sentences = nltk.sent_tokenize(text)\n",
        "            for sentence in sentences:\n",
        "                words = nltk.word_tokenize(sentence)\n",
        "                tagged = nltk.pos_tag(words)\n",
        "                for (word, tag) in tagged:\n",
        "                    if tag == 'PRP': # If the word is a proper noun\n",
        "                        count = count + 1 \n",
        "        \n",
        "            return(count) \n",
        "        Personal_Pronouns=Proper_Noun_Extractor(article) # personal pronoun\n",
        "    \n",
        "\n",
        "        #function for sentiment analysis\n",
        "        def Sentiment_Analysis(text):\n",
        "            sentiment = TextBlob(text).sentiment\n",
        "            return (sentiment.polarity)\n",
        "    \n",
        "        Polarity_Score = Sentiment_Analysis(article) # polarity score \n",
        "  \n",
        "        def Sentiment_Analysis(text):\n",
        "            sentiment = TextBlob(text).sentiment\n",
        "            return (sentiment.subjectivity)\n",
        "    \n",
        "        Subjectivity_Score = Sentiment_Analysis(article) # subjective score\n",
        "        \n",
        "        \n",
        "        #method to count average syllable count in words\n",
        "        word=article.replace(' ','')\n",
        "        syllable_count = 0\n",
        "        for w in word:\n",
        "            \n",
        "            if(w=='a' or w=='e' or w=='i' or w=='o' or w=='y' or w=='u' or w=='A' or w=='E' or w=='I' or w=='O' or w=='U' or w=='Y'):\n",
        "                syllable_count=syllable_count+1\n",
        "\n",
        "        Syllable_Per_Word=(syllable_count/len(article.split()))\n",
        "        \n",
        "        # calculate average word length \n",
        "        Average_Word_Length=len(article.replace(' ',''))/len(article.split())\n",
        "        \n",
        "        # calculate percentage of complex word\n",
        "        Percentage_of_Complex_Words = Complex_Word_Count / Word_Count * 100\n",
        "\n",
        "        # insret the all analysis score in the blank list \n",
        "        data.insert(i,[url_id,url,Positive_score, Negative_score, Polarity_Score, Subjectivity_Score, Average_Sentence_Length, Percentage_of_Complex_Words, Fog_Index, Average_Number_of_Words_Per_Sentence , Complex_Word_Count, Word_Count,Syllable_Per_Word, Personal_Pronouns, Average_Word_Length])\n",
        "        \n",
        "\n",
        "# time to call the main function   \n",
        "if __name__ == '__main__' :  \n",
        "    Text_Analysis()\n",
        "        \n"
      ],
      "metadata": {
        "id": "GY3tBQ_aL81x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a data frame with the values of all the text analysis\n",
        "df = pd.DataFrame(data,columns=['url_id','url','Positive_score','Negative_score','Polarity_Score','Subjectivity_Score', 'Average_Sentence_Length','Percentage_of_Complex_Words', 'Fog_Index', 'Average_Number_of_Words_Per_Sentence' , 'Complex_Word_Count', 'Word_Count', 'Syllable_Per_Word','Personal_Pronouns', 'Average_Word_Length'])\n",
        "df.to_csv('Output_Data.csv') # save the data frame in a csv file \n",
        "df # show the final data frame "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "JD0mCswPMA6L",
        "outputId": "69125187-a309-45c5-bf60-5cd0b11f2769"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     url_id                                                url  \\\n",
              "0        37  https://insights.blackcoffer.com/ai-in-healthc...   \n",
              "1        38  https://insights.blackcoffer.com/what-if-the-c...   \n",
              "2        39  https://insights.blackcoffer.com/what-jobs-wil...   \n",
              "3        40  https://insights.blackcoffer.com/will-machine-...   \n",
              "4        41  https://insights.blackcoffer.com/will-ai-repla...   \n",
              "..      ...                                                ...   \n",
              "106     146  https://insights.blackcoffer.com/blockchain-fo...   \n",
              "107     147  https://insights.blackcoffer.com/the-future-of...   \n",
              "108     148  https://insights.blackcoffer.com/big-data-anal...   \n",
              "109     149  https://insights.blackcoffer.com/business-anal...   \n",
              "110     150  https://insights.blackcoffer.com/challenges-an...   \n",
              "\n",
              "     Positive_score  Negative_score  Polarity_Score  Subjectivity_Score  \\\n",
              "0                77              33        0.136936            0.463364   \n",
              "1                65              37        0.074693            0.433596   \n",
              "2                73              33        0.111470            0.483201   \n",
              "3                72              25        0.141419            0.487387   \n",
              "4                59              26        0.053178            0.509139   \n",
              "..              ...             ...             ...                 ...   \n",
              "106              28              27        0.035488            0.402814   \n",
              "107              45              12        0.074727            0.389435   \n",
              "108              30              43        0.040319            0.417892   \n",
              "109              33               4        0.208748            0.546448   \n",
              "110              45              38        0.124963            0.459020   \n",
              "\n",
              "     Average_Sentence_Length  Percentage_of_Complex_Words  Fog_Index  \\\n",
              "0                    10162.0                    29.934761     721.92   \n",
              "1                     6861.0                    29.293051     567.40   \n",
              "2                     9220.0                    30.580480     684.87   \n",
              "3                     8061.0                    29.613999     660.88   \n",
              "4                     8927.0                    29.369319     699.95   \n",
              "..                       ...                          ...        ...   \n",
              "106                   4895.0                    29.223351     369.76   \n",
              "107                   7979.0                    29.090719     620.72   \n",
              "108                   5903.0                    30.363456     465.90   \n",
              "109                   4105.0                    30.336379     291.93   \n",
              "110                   5271.0                    30.732711     422.21   \n",
              "\n",
              "     Average_Number_of_Words_Per_Sentence  Complex_Word_Count  Word_Count  \\\n",
              "0                                  1790.0                3579       11956   \n",
              "1                                  1409.0                2424        8275   \n",
              "2                                  1700.0                3340       10922   \n",
              "3                                  1650.0                2877        9715   \n",
              "4                                  1739.0                3134       10671   \n",
              "..                                    ...                 ...         ...   \n",
              "106                                 911.0                1697        5807   \n",
              "107                                1550.0                2777        9546   \n",
              "108                                1155.0                2147        7071   \n",
              "109                                 715.0                1461        4816   \n",
              "110                                1045.0                1942        6319   \n",
              "\n",
              "     Syllable_Per_Word  Personal_Pronouns  Average_Word_Length  \n",
              "0             2.248045                 22             5.677095  \n",
              "1             1.948900                 51             4.869411  \n",
              "2             2.187647                 28             5.423529  \n",
              "3             1.951515                 49             4.885455  \n",
              "4             2.015526                 53             5.133410  \n",
              "..                 ...                ...                  ...  \n",
              "106           2.109769                 23             5.373216  \n",
              "107           2.042581                 24             5.147742  \n",
              "108           2.069264                 14             5.110823  \n",
              "109           2.281119                  9             5.741259  \n",
              "110           2.034450                 22             5.044019  \n",
              "\n",
              "[111 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b9977d69-b6f5-452f-bf8f-1e59f34dfec9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url_id</th>\n",
              "      <th>url</th>\n",
              "      <th>Positive_score</th>\n",
              "      <th>Negative_score</th>\n",
              "      <th>Polarity_Score</th>\n",
              "      <th>Subjectivity_Score</th>\n",
              "      <th>Average_Sentence_Length</th>\n",
              "      <th>Percentage_of_Complex_Words</th>\n",
              "      <th>Fog_Index</th>\n",
              "      <th>Average_Number_of_Words_Per_Sentence</th>\n",
              "      <th>Complex_Word_Count</th>\n",
              "      <th>Word_Count</th>\n",
              "      <th>Syllable_Per_Word</th>\n",
              "      <th>Personal_Pronouns</th>\n",
              "      <th>Average_Word_Length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>37</td>\n",
              "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
              "      <td>77</td>\n",
              "      <td>33</td>\n",
              "      <td>0.136936</td>\n",
              "      <td>0.463364</td>\n",
              "      <td>10162.0</td>\n",
              "      <td>29.934761</td>\n",
              "      <td>721.92</td>\n",
              "      <td>1790.0</td>\n",
              "      <td>3579</td>\n",
              "      <td>11956</td>\n",
              "      <td>2.248045</td>\n",
              "      <td>22</td>\n",
              "      <td>5.677095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38</td>\n",
              "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
              "      <td>65</td>\n",
              "      <td>37</td>\n",
              "      <td>0.074693</td>\n",
              "      <td>0.433596</td>\n",
              "      <td>6861.0</td>\n",
              "      <td>29.293051</td>\n",
              "      <td>567.40</td>\n",
              "      <td>1409.0</td>\n",
              "      <td>2424</td>\n",
              "      <td>8275</td>\n",
              "      <td>1.948900</td>\n",
              "      <td>51</td>\n",
              "      <td>4.869411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>39</td>\n",
              "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
              "      <td>73</td>\n",
              "      <td>33</td>\n",
              "      <td>0.111470</td>\n",
              "      <td>0.483201</td>\n",
              "      <td>9220.0</td>\n",
              "      <td>30.580480</td>\n",
              "      <td>684.87</td>\n",
              "      <td>1700.0</td>\n",
              "      <td>3340</td>\n",
              "      <td>10922</td>\n",
              "      <td>2.187647</td>\n",
              "      <td>28</td>\n",
              "      <td>5.423529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40</td>\n",
              "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
              "      <td>72</td>\n",
              "      <td>25</td>\n",
              "      <td>0.141419</td>\n",
              "      <td>0.487387</td>\n",
              "      <td>8061.0</td>\n",
              "      <td>29.613999</td>\n",
              "      <td>660.88</td>\n",
              "      <td>1650.0</td>\n",
              "      <td>2877</td>\n",
              "      <td>9715</td>\n",
              "      <td>1.951515</td>\n",
              "      <td>49</td>\n",
              "      <td>4.885455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41</td>\n",
              "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
              "      <td>59</td>\n",
              "      <td>26</td>\n",
              "      <td>0.053178</td>\n",
              "      <td>0.509139</td>\n",
              "      <td>8927.0</td>\n",
              "      <td>29.369319</td>\n",
              "      <td>699.95</td>\n",
              "      <td>1739.0</td>\n",
              "      <td>3134</td>\n",
              "      <td>10671</td>\n",
              "      <td>2.015526</td>\n",
              "      <td>53</td>\n",
              "      <td>5.133410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>146</td>\n",
              "      <td>https://insights.blackcoffer.com/blockchain-fo...</td>\n",
              "      <td>28</td>\n",
              "      <td>27</td>\n",
              "      <td>0.035488</td>\n",
              "      <td>0.402814</td>\n",
              "      <td>4895.0</td>\n",
              "      <td>29.223351</td>\n",
              "      <td>369.76</td>\n",
              "      <td>911.0</td>\n",
              "      <td>1697</td>\n",
              "      <td>5807</td>\n",
              "      <td>2.109769</td>\n",
              "      <td>23</td>\n",
              "      <td>5.373216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>147</td>\n",
              "      <td>https://insights.blackcoffer.com/the-future-of...</td>\n",
              "      <td>45</td>\n",
              "      <td>12</td>\n",
              "      <td>0.074727</td>\n",
              "      <td>0.389435</td>\n",
              "      <td>7979.0</td>\n",
              "      <td>29.090719</td>\n",
              "      <td>620.72</td>\n",
              "      <td>1550.0</td>\n",
              "      <td>2777</td>\n",
              "      <td>9546</td>\n",
              "      <td>2.042581</td>\n",
              "      <td>24</td>\n",
              "      <td>5.147742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>148</td>\n",
              "      <td>https://insights.blackcoffer.com/big-data-anal...</td>\n",
              "      <td>30</td>\n",
              "      <td>43</td>\n",
              "      <td>0.040319</td>\n",
              "      <td>0.417892</td>\n",
              "      <td>5903.0</td>\n",
              "      <td>30.363456</td>\n",
              "      <td>465.90</td>\n",
              "      <td>1155.0</td>\n",
              "      <td>2147</td>\n",
              "      <td>7071</td>\n",
              "      <td>2.069264</td>\n",
              "      <td>14</td>\n",
              "      <td>5.110823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>149</td>\n",
              "      <td>https://insights.blackcoffer.com/business-anal...</td>\n",
              "      <td>33</td>\n",
              "      <td>4</td>\n",
              "      <td>0.208748</td>\n",
              "      <td>0.546448</td>\n",
              "      <td>4105.0</td>\n",
              "      <td>30.336379</td>\n",
              "      <td>291.93</td>\n",
              "      <td>715.0</td>\n",
              "      <td>1461</td>\n",
              "      <td>4816</td>\n",
              "      <td>2.281119</td>\n",
              "      <td>9</td>\n",
              "      <td>5.741259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>150</td>\n",
              "      <td>https://insights.blackcoffer.com/challenges-an...</td>\n",
              "      <td>45</td>\n",
              "      <td>38</td>\n",
              "      <td>0.124963</td>\n",
              "      <td>0.459020</td>\n",
              "      <td>5271.0</td>\n",
              "      <td>30.732711</td>\n",
              "      <td>422.21</td>\n",
              "      <td>1045.0</td>\n",
              "      <td>1942</td>\n",
              "      <td>6319</td>\n",
              "      <td>2.034450</td>\n",
              "      <td>22</td>\n",
              "      <td>5.044019</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>111 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b9977d69-b6f5-452f-bf8f-1e59f34dfec9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b9977d69-b6f5-452f-bf8f-1e59f34dfec9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b9977d69-b6f5-452f-bf8f-1e59f34dfec9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('Output_Data.csv') # download the csv file  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "XGwDLEULPwnr",
        "outputId": "63851c6c-b27e-4ea4-c955-09b9ed6b33ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0c6ce20a-d36a-4c8c-981a-d245ccd68894\", \"Output_Data.csv\", 25699)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}